{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-15T01:41:54.870257Z",
     "start_time": "2024-05-15T01:41:54.810378Z"
    }
   },
   "source": [
    "from pydantic.main import Model\n",
    "\n",
    "from agent import Agent\n",
    "from tetris.game import Game\n",
    "import numpy as np\n",
    "import nest_asyncio\n",
    "from tqdm import tqdm\n",
    "nest_asyncio.apply()"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Evolutionary Algorithm\n",
    "Fitness:\n",
    "- Score weights based on average final Tetris score over N random games\n",
    "Selection:\n",
    "- Use fitness proportional selection to select top K performing options\n",
    "Reproduction:\n",
    "- Parent A contributes 1-4 random genes and Parent B contributes the compliment\n",
    "Mutation:\n",
    "- Apply m operations in sequence\n",
    "  - No-op\n",
    "  - Swap genes (i, j) \n",
    "  - Add/subtract value from gene i\n",
    "  - Double/half value of gene i   "
   ],
   "id": "9eeb89822eec1237"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T02:31:13.293962Z",
     "start_time": "2024-05-15T02:31:13.244027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel, ConfigDict\n",
    "from typing import List, Tuple, Any, Awaitable, Callable\n",
    "\n",
    "import concurrent.futures\n",
    "import asyncio\n",
    "\n",
    "class EvoAlgo(BaseModel):\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "\n",
    "    selection_rate: int = 0.2\n",
    "    mutation_rate: float = 0.2\n",
    "    crossover_rate: float = 0.2\n",
    "    increment_vals: List[float] = [0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1.0]\n",
    "    multiply_vals: List[float] = [0.5, 0.75, 1.33, 2]\n",
    "    weight_constraint: Tuple[float, float] = (0, 10)\n",
    "    population: List[Agent] = []\n",
    "    best_weights: List[np.ndarray] = []\n",
    "    best_scores: List[float] = []\n",
    "    seed: int = 87\n",
    "    rng: np.random.Generator = np.random.default_rng(seed)\n",
    "    \n",
    "    def minimize(self, objective: Callable, num_generations: int = 10, population_size: int = 50) -> Tuple[List[np.ndarray], List[float], List[Agent]]:\n",
    "        weights = self.rng.random(size=(population_size, 5)) * self.weight_constraint[1]\n",
    "        agents = [Agent(weights=w) for w in weights]\n",
    "        for g in range(num_generations):\n",
    "            scores = []\n",
    "            if g > 0:\n",
    "                # Start new generation\n",
    "                keep_agents = self.select(agents, scores)\n",
    "                child_agents = self.crossover(keep_agents)\n",
    "                mutated_agents = self.mutate(child_agents)\n",
    "                agents = mutated_agents\n",
    "            with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "                scores = executor.map(objective, agents)\n",
    "            scores = list(scores)\n",
    "            self.best_scores.append(np.max(scores))\n",
    "            self.best_weights.append(agents[np.argmax(scores)].weights)\n",
    "            print(f\"Best score was {self.best_scores[-1]} with weights {self.best_weights[-1]}\")\n",
    "            \n",
    "        return self.best_weights, self.best_scores, agents\n",
    "    \n",
    "    def select(self, agents: List[Agent], scores: List[float]) -> List[Agent]:\n",
    "        \"\"\"Stochastic uniform sampling\"\"\"\n",
    "        fps_scores = np.array(scores) / sum(scores)\n",
    "        order = np.argsort(fps_scores)\n",
    "        fps_scores = fps_scores[order]\n",
    "        agents = [agents[i] for i in order]\n",
    "        \n",
    "        roulette_bins = np.cumsum(fps_scores)\n",
    "        \n",
    "        # Generate evenly spaced pointers\n",
    "        N = len(agents)\n",
    "        pointers = np.arange(N - 1) / (N - 1)\n",
    "        offset = np.random.rand()  # Spin the roulette wheel!\n",
    "        pointers = pointers + offset\n",
    "        pointers[pointers > 1] = pointers[pointers > 1] - 1\n",
    "        # Use digitize to select items\n",
    "        keep_inds = np.digitize(pointers, roulette_bins)\n",
    "        return [agents[i] for i in keep_inds]\n",
    "    \n",
    "    def crossover(self, agents: List[Agent]) -> List[Agent]:\n",
    "        def _crossover_fn(a: Agent, b: Agent) -> Agent:\n",
    "            genes = self.rng.permutation(5)\n",
    "            selection = self.rng.choice(np.arange(4) + 1)\n",
    "            new_weight = np.zeros(5)\n",
    "            # Genetic selection should be complementary\n",
    "            a_genes = genes[:selection]\n",
    "            b_genes = genes[selection:]\n",
    "            new_weight[a_genes] = a.weights[a_genes]\n",
    "            new_weight[b_genes] = b.weights[b_genes]\n",
    "            return Agent(weights=new_weight)\n",
    "        \n",
    "        new_agents = []\n",
    "        for agent in agents:\n",
    "            if self.rng.random() < self.crossover_rate:\n",
    "                agent_coparent = self.rng.choice(agents)\n",
    "                new_agents.append(_crossover_fn(agent, agent_coparent))\n",
    "            else:\n",
    "                new_agents.append(agent)\n",
    "        return new_agents\n",
    "    \n",
    "    def _increment_gene(self, agent: Agent) -> Agent:\n",
    "        i = self.rng.choice(5)\n",
    "        val = self.rng.choice([-1, 1]) * self.rng.choice(self.increment_vals)\n",
    "        agent.weights[i] += val\n",
    "        agent.weights = np.clip(agent.weights, self.weight_constraint[0], self.weight_constraint[1])\n",
    "        return agent\n",
    "    \n",
    "    def _multiply_gene(self, agent: Agent) -> Agent:\n",
    "        i = self.rng.choice(5)\n",
    "        val = self.rng.choice(self.multiply_vals)\n",
    "        agent.weights[i] *= val\n",
    "        agent.weights = np.clip(agent.weights, self.weight_constraint[0], self.weight_constraint[1])\n",
    "        return agent\n",
    "    \n",
    "    def _swap_gene(self, agent: Agent) -> Agent:\n",
    "        i, j = self.rng.choice(5, size=2, replace=False)\n",
    "        agent.weights[[j, i]] = agent.weights[[i, j]]\n",
    "        return agent\n",
    "    \n",
    "    def mutate(self, agents: List[Agent]) -> List[Agent]:\n",
    "        mutation_fns = [self._swap_gene, self._increment_gene, self._multiply_gene]\n",
    "        mutation_fn_weights = [0.2, 0.6, 0.2]\n",
    "        mutated_agents = []\n",
    "        for agent in agents:\n",
    "            if self.rng.random() < self.mutation_rate:\n",
    "                mutation_fn = self.rng.choice(mutation_fns, p=mutation_fn_weights)\n",
    "                mutated_agents.append(mutation_fn(agent))\n",
    "            else:\n",
    "                mutated_agents.append(agent)\n",
    "        # Ensure the best agent has at least one candidate\n",
    "        mutated_agents[-1] = Agent(weights=self.best_weights[-1])\n",
    "        return mutated_agents"
   ],
   "id": "bdef64c3c861a67d",
   "outputs": [],
   "execution_count": 132
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T02:31:15.885506Z",
     "start_time": "2024-05-15T02:31:15.878114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "GAME_SEED = 87\n",
    "async def objective(agent: Agent) -> float:\n",
    "    game = Game(agent, seed=GAME_SEED)\n",
    "    results = []\n",
    "    async for item in game.run():\n",
    "        results.append(item)\n",
    "    return game.score"
   ],
   "id": "ad0f5306b8597a7f",
   "outputs": [],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T02:31:18.606804Z",
     "start_time": "2024-05-15T02:31:18.601397Z"
    }
   },
   "cell_type": "code",
   "source": "algo = EvoAlgo(mutation_rate=0.8)",
   "id": "f749a10e1824cead",
   "outputs": [],
   "execution_count": 134
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T02:31:19.447535Z",
     "start_time": "2024-05-15T02:31:19.444861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_agent(agent: Agent) -> float:\n",
    "    return asyncio.run(objective(agent))\n"
   ],
   "id": "f5654da832f10e6a",
   "outputs": [],
   "execution_count": 135
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T02:49:08.313980Z",
     "start_time": "2024-05-15T02:31:22.021612Z"
    }
   },
   "cell_type": "code",
   "source": "algo.minimize(process_agent, num_generations=10, population_size=100)",
   "id": "da7f95d276f2c797",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score was 41800 with weights [7.16486926 3.70265966 1.0339912  0.43048801 0.65572238]\n",
      "Best score was 41800 with weights [6.93881597 1.96453073 9.88761146 0.34983371 1.65335652]\n",
      "Best score was 41800 with weights [1.38435367 9.47622884 0.         5.37111807 1.26766473]\n",
      "Best score was 41800 with weights [7.16486926 0.2854934  4.80265966 1.86097601 0.65572238]\n",
      "Best score was 41800 with weights [0.01       2.47453073 9.99       3.28940798 1.65335652]\n",
      "Best score was 41800 with weights [ 2.91706346  2.47453073 10.          3.01054717  1.65335652]\n",
      "Best score was 41800 with weights [ 1.73470399  1.95453073 10.          0.93048801  1.49572238]\n",
      "Best score was 44000 with weights [1.73470399 1.86097601 9.99       0.         0.64572238]\n",
      "Best score was 41800 with weights [ 2.90706346  1.95453073 10.          1.88097601  1.49572238]\n",
      "Best score was 49400 with weights [1.66097601 0.1527467  4.80265966 0.         0.65572238]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([array([ 7.16486926,  3.70265966,  0.43048801,  1.0439912 , -0.34427762]),\n",
       "  array([13.87763194,  1.96453073,  9.68761146,  0.34983371,  1.65335652]),\n",
       "  array([1.38435367, 9.47622884, 1.26766473, 5.36111807, 0.        ]),\n",
       "  array([7.16486926, 0.2854934 , 9.60531933, 1.86097601, 0.45572238]),\n",
       "  array([0.01      , 2.47453073, 7.4925    , 3.23940798, 1.65335652]),\n",
       "  array([ 2.41706346,  2.47453073, 10.        ,  3.01054717,  1.55335652]),\n",
       "  array([ 1.73470399,  1.95453073, 10.        ,  0.93048801,  1.49572238]),\n",
       "  array([1.66097601, 1.73470399, 9.99      , 0.64572238, 0.        ]),\n",
       "  array([ 2.95706346,  1.95453073, 10.        ,  1.88097601,  1.50572238]),\n",
       "  array([1.66097601, 0.1527467 , 4.80265966, 0.        , 0.66572238])],\n",
       " [41800, 41800, 41800, 41800, 41800, 41800, 41800, 44000, 41800, 49400])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 136
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T03:06:55.114472Z",
     "start_time": "2024-05-15T03:06:55.104532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "GAME_SEEDS = [87, 42, 101]\n",
    "async def objective(agent: Agent, seed) -> float:\n",
    "    game = Game(agent, seed=seed)\n",
    "    results = []\n",
    "    async for item in game.run():\n",
    "        results.append(item)\n",
    "    return game.score\n",
    "\n",
    "def process_agent(agent: Agent) -> float:\n",
    "    scores = []\n",
    "    for seed in GAME_SEEDS:\n",
    "        scores.append(asyncio.run(objective(agent, seed)))\n",
    "    return np.mean(scores)\n"
   ],
   "id": "ed8af890d01c94d1",
   "outputs": [],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T03:06:59.883637Z",
     "start_time": "2024-05-15T03:06:59.877866Z"
    }
   },
   "cell_type": "code",
   "source": "algo = EvoAlgo(mutation_rate=0.8, crossover_rate=0.4)",
   "id": "4dc04f75d3e3fb2d",
   "outputs": [],
   "execution_count": 140
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T03:22:37.169700Z",
     "start_time": "2024-05-15T03:07:02.780890Z"
    }
   },
   "cell_type": "code",
   "source": "algo.minimize(process_agent, num_generations=10, population_size=20)",
   "id": "fba2a0f01bef5e72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score was 38450.0 with weights [0.74980881 5.30095162 8.04020742 3.71680968 2.39185946]\n",
      "Best score was 38450.0 with weights [0.74980881 2.76761358 8.54020742 3.71680968 2.02725388]\n",
      "Best score was 38450.0 with weights [2.31305573 6.27873695 6.07579239 3.71680968 2.39185946]\n",
      "Best score was 38450.0 with weights [0.84980881 6.27873695 8.04020742 3.81680968 2.39185946]\n",
      "Best score was 38450.0 with weights [0.84980881 6.27873695 8.04020742 3.81680968 2.44185946]\n",
      "Best score was 38450.0 with weights [2.31305573 6.27873695 8.04020742 3.79680968 2.44185946]\n",
      "Best score was 38450.0 with weights [2.31305573 6.29873695 7.99020742 3.79680968 2.44185946]\n",
      "Best score was 38450.0 with weights [0.79980881 6.27873695 8.04020742 3.71680968 2.44185946]\n",
      "Best score was 38450.0 with weights [2.31305573 6.29873695 7.99020742 2.69680968 2.44185946]\n",
      "Best score was 38450.0 with weights [2.31305573 6.29873695 6.99020742 2.69680968 2.44185946]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([array([3.73680968, 5.32095162, 8.04020742, 0.74980881, 2.39185946]),\n",
       "  array([0.74980881, 2.76761358, 8.64020742, 3.71680968, 1.82725388]),\n",
       "  array([2.31305573, 3.71680968, 6.07579239, 6.27873695, 1.59058654]),\n",
       "  array([0.84980881, 6.27873695, 8.04020742, 3.81680968, 3.44185946]),\n",
       "  array([0.79980881, 6.27873695, 8.04020742, 3.81680968, 2.44185946]),\n",
       "  array([2.31305573, 6.29873695, 8.04020742, 3.79680968, 2.44185946]),\n",
       "  array([2.26305573, 6.29873695, 7.99020742, 2.79680968, 2.44185946]),\n",
       "  array([0.79980881, 6.26873695, 8.04020742, 3.71680968, 2.44185946]),\n",
       "  array([2.31305573, 2.44185946, 7.99020742, 2.69680968, 6.29873695]),\n",
       "  array([2.31305573, 6.29873695, 6.99020742, 2.69680968, 2.44185946])],\n",
       " [38450.0,\n",
       "  38450.0,\n",
       "  38450.0,\n",
       "  38450.0,\n",
       "  38450.0,\n",
       "  38450.0,\n",
       "  38450.0,\n",
       "  38450.0,\n",
       "  38450.0,\n",
       "  38450.0])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 141
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import concurrent.futures\n",
    "import asyncio\n",
    "\n",
    "num_trials = 10\n",
    "game_seed = 42\n",
    "\n",
    "async def objective(agent: Agent) -> float:\n",
    "    game = Game(agent, seed=game_seed)\n",
    "    async for _ in game.run():\n",
    "        continue\n",
    "    return game.score\n",
    "\n",
    "def process_agent(agent: Agent) -> float:\n",
    "    return asyncio.run(objective(agent))\n",
    "\n",
    "\n",
    "agents = [Agent(np.random.randn(5)) for _ in range(num_trials)]\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    scores = executor.map(process_agent, agents)\n",
    "scores = list(scores)"
   ],
   "id": "87784ae9ef5fd473"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
